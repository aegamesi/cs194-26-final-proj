{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = \"/Users/eli/Downloads/2011_09_26/2011_09_26_drive_0002_sync/image_00/data/\"\n",
    "basedir = \"/Users/eli/Downloads/2011_09_26 2/2011_09_26_drive_0027_sync/image_03/data/\"\n",
    "#basedir = \"/Users/eli/Dropbox/Code/school/cs194-26/final_proj/streetviewimgs2/\"\n",
    "#basedir = \"/Users/eli/Downloads/2011_09_28/2011_09_28_drive_0002_sync/image_03/data/\"\n",
    "basedir = \"/Users/eli/Downloads/2011_10_03/2011_10_03_drive_0042_sync/image_00/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "import io\n",
    "import importlib\n",
    "import functools\n",
    "import math\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# first party\n",
    "import common\n",
    "importlib.reload(common)\n",
    "\n",
    "# third party\n",
    "from contexttimer import Timer\n",
    "\n",
    "# SciPy / OpenCV\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import skimage.io as skio\n",
    "import skimage as sk\n",
    "import IPython\n",
    "import PIL.Image\n",
    "import IPython.display\n",
    "import scipy.ndimage\n",
    "import scipy\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lerp(a, b, t):\n",
    "    return (b - a) * t + a\n",
    "\n",
    "def combine(a, b):\n",
    "    return np.multiply(a, (1 - np.ma.masked_where(b != 0, b).mask)) + b\n",
    "\n",
    "def combine_mask(a, b, mask):\n",
    "    return np.multiply(a, 1 - mask) + np.multiply(b, mask)\n",
    "\n",
    "def combine_many(ims):\n",
    "    return functools.reduce(lambda a, b: combine(b, a), ims[::-1])\n",
    "\n",
    "def transform_pts(pts, M):\n",
    "    \"\"\"\n",
    "    pts is like np.float32([[x, y], [x1, y1], [x2, y2]]...)\n",
    "    \n",
    "    \"\"\"\n",
    "    trans = cv2.perspectiveTransform(pts.reshape(-1, 1, 2), M)\n",
    "    return trans.reshape(pts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_homography(im1, im2):\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    \n",
    "    kp1, des1 = sift.detectAndCompute(im1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(im2, None)\n",
    "    \n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "    \n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.9*n.distance:\n",
    "            good.append(m)\n",
    "            \n",
    "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    # M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 20.0)\n",
    "    M = cv2.estimateRigidTransform(src_pts, dst_pts, False)\n",
    "    if M is None:\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 20.0)\n",
    "        print(\"***\")\n",
    "    else:\n",
    "        M = np.vstack([M, np.float32([[0, 0, 1]])])\n",
    "    #matchesMask = mask.ravel().tolist()\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lerpiform(w, h, M, t):\n",
    "    \"\"\"\n",
    "    Computes A_(b -> a, t) from T_(b -> a)\n",
    "    \n",
    "    Computes the matrix needed to transform an image warped from the viewport (0 -> w, 0 -> h)\n",
    "    and then lerp it back to the viewport with parameter t.\n",
    "    \"\"\"\n",
    "    \n",
    "    # transform corners to the inner image's corners\n",
    "    corners = np.float32([[0,0], [0,h-1], [w-1,h-1], [w-1,0] ])\n",
    "    inner_corners = transform_pts(corners, M)\n",
    "\n",
    "    # lerp inner corners towards the outer corners\n",
    "    lerped = lerp(inner_corners, corners, t)\n",
    "\n",
    "    # find a new matrix to go from outer corners to lerped inner corners\n",
    "    M2 = cv2.getPerspectiveTransform(inner_corners, lerped)\n",
    "\n",
    "    return M2\n",
    "\n",
    "def lerpywarp(im_inner, im_outer, M, t):\n",
    "    h, w = im_inner.shape\n",
    "    M2 = lerpiform(w, h, M, t)\n",
    "\n",
    "    im_inner_2 = cv2.warpPerspective(im_inner, M2 @ M, (w, h))\n",
    "    im_outer_2 = cv2.warpPerspective(im_outer, M2, (w, h))\n",
    "\n",
    "    return im_inner_2 #(im_outer_2 + im_inner_2) * 0.5#combine(im_outer_2, im_inner_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_homographies(imgs):\n",
    "    \"\"\"\n",
    "    Takes in a list of images, computes homographies between each image\n",
    "    and its successive image, the first one is always the identity matrix.\n",
    "    \"\"\"\n",
    "    args = [(imgs[i + 1], imgs[i]) for i in range(len(imgs) - 1)]\n",
    "    with Pool() as p:\n",
    "        homs = p.starmap(find_homography, args)\n",
    "    \n",
    "    return [np.identity(3)] + homs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs = [common.imread(basedir + \"%010d.png\" % i, as_float=False) for i in range(0, 188, 1)]\n",
    "imgs = [cv2.imread(basedir + \"%010d.png\" % i, 0) for i in range(0, 1170, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed 1170 homographies in 167.499933881998\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    # Ts = [np.identity(3)] + [find_homography(imgs[i + 1], imgs[i]) for i in range(len(imgs) - 1)]\n",
    "    Ts = pairwise_homographies(imgs)\n",
    "print(\"computed {} homographies in {}\".format(len(Ts), t.elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_frame(t, context):\n",
    "    imgs, Ts, mask, w, h, draw_distance = context\n",
    "    lower = int(math.floor(t))\n",
    "    A = lerpiform(w, h, Ts[lower + 1], t - lower)\n",
    "\n",
    "    transformed_images = []\n",
    "    im = None\n",
    "    for j in range(lower, min(len(imgs), lower + draw_distance)):\n",
    "        M = functools.reduce(np.dot, [A] + Ts[lower + 1:j + 1])\n",
    "        im_trans = cv2.warpPerspective(imgs[j], M, (w, h))\n",
    "        mask_trans = cv2.warpPerspective(mask, M, (w, h))\n",
    "        \n",
    "        if im is None:\n",
    "            im = im_trans\n",
    "        else:\n",
    "            im = combine_mask(im, im_trans, mask_trans)\n",
    "            \n",
    "    return im\n",
    "    \n",
    "def final_video(imgs, Ts, speed=1.0, draw_distance=30):\n",
    "    h, w = imgs[0].shape[:2]\n",
    "    \n",
    "    # compute mask\n",
    "    mask_r = 32\n",
    "    mask = np.zeros((h, w))\n",
    "    mask[mask_r:-mask_r,mask_r:-mask_r] = 1.0\n",
    "    mask = scipy.ndimage.gaussian_filter(mask, sigma=(mask_r * 0.5))\n",
    "    if len(imgs[0].shape) == 3:\n",
    "        mask = np.dstack([mask] * imgs[0].shape[-1])\n",
    "    \n",
    "    # compute timestamps to make frames at\n",
    "    timestamps = []\n",
    "    t = 0.0\n",
    "    while t < len(imgs) - 1:\n",
    "        timestamps.append(t)\n",
    "        lower = int(math.floor(t))\n",
    "        det = np.linalg.det(Ts[lower + 1])\n",
    "        t += det / speed\n",
    "        \n",
    "    with Pool() as p:\n",
    "        context = (imgs, Ts, mask, w, h, draw_distance)\n",
    "        frames = p.starmap(_compute_frame, [(t, context) for t in timestamps], chunksize=20)\n",
    "        \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    frames = final_video(imgs, Ts, speed=1.0, draw_distance=100)\n",
    "print(\"computed {} frames in {}\".format(len(frames), t.elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common.videosave(\"out_dataset_3_bw_masked_speed1_draw100.mp4\", frames, fps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
