{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = \"/Users/eli/Downloads/2011_09_26/2011_09_26_drive_0002_sync/image_00/data/\"\n",
    "#basedir = \"/Users/eli/Dropbox/Code/school/cs194-26/final_proj/streetviewimgs2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import io\n",
    "import importlib\n",
    "import functools\n",
    "\n",
    "import common\n",
    "importlib.reload(common)\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import skimage.io as skio\n",
    "import skimage as sk\n",
    "import IPython\n",
    "import PIL.Image\n",
    "import IPython.display\n",
    "import scipy.ndimage\n",
    "import scipy\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lerp(a, b, t):\n",
    "    return (b - a) * t + a\n",
    "\n",
    "def combine(a, b):\n",
    "    return np.multiply(a, (1 - np.ma.masked_where(b != 0, b).mask)) + b\n",
    "\n",
    "def combine_many(ims):\n",
    "    return functools.reduce(lambda a, b: combine(b, a), ims[::-1])\n",
    "\n",
    "def transform_pts(pts, M):\n",
    "    \"\"\"\n",
    "    pts is like np.float32([[x, y], [x1, y1], [x2, y2]]...)\n",
    "    \n",
    "    \"\"\"\n",
    "    trans = cv2.perspectiveTransform(pts.reshape(-1, 1, 2), M)\n",
    "    return trans.reshape(pts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_homography(im1, im2):\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    \n",
    "    kp1, des1 = sift.detectAndCompute(im1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(im2, None)\n",
    "    \n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "    \n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.9*n.distance:\n",
    "            good.append(m)\n",
    "            \n",
    "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    # M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 20.0)\n",
    "    M = cv2.estimateRigidTransform(src_pts, dst_pts, False)\n",
    "    M = np.vstack([M, np.float32([[0, 0, 1]])])\n",
    "    #matchesMask = mask.ravel().tolist()\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lerpiform(w, h, M, t):\n",
    "    \"\"\"\n",
    "    Computes A_(b -> a, t) from T_(b -> a)\n",
    "    \n",
    "    Computes the matrix needed to transform an image warped from the viewport (0 -> w, 0 -> h)\n",
    "    and then lerp it back to the viewport with parameter t.\n",
    "    \"\"\"\n",
    "    \n",
    "    # transform corners to the inner image's corners\n",
    "    corners = np.float32([[0,0], [0,h-1], [w-1,h-1], [w-1,0] ])\n",
    "    inner_corners = transform_pts(corners, M)\n",
    "\n",
    "    # lerp inner corners towards the outer corners\n",
    "    lerped = lerp(inner_corners, corners, t)\n",
    "\n",
    "    # find a new matrix to go from outer corners to lerped inner corners\n",
    "    M2 = cv2.getPerspectiveTransform(inner_corners, lerped)\n",
    "\n",
    "    return M2\n",
    "\n",
    "def lerpywarp(im_inner, im_outer, M, t):\n",
    "    h, w = im_inner.shape\n",
    "    M2 = lerpiform(w, h, M, t)\n",
    "\n",
    "    im_inner_2 = cv2.warpPerspective(im_inner, M2 @ M, (w, h))\n",
    "    im_outer_2 = cv2.warpPerspective(im_outer, M2, (w, h))\n",
    "\n",
    "    return im_inner_2 #(im_outer_2 + im_inner_2) * 0.5#combine(im_outer_2, im_inner_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [cv2.imread(basedir + \"%010d.png\" % i, 0) for i in range(0, 76, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ts = [np.identity(3)] + [find_homography(imgs[i + 1], imgs[i]) for i in range(len(imgs) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ts_old = Ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = imgs[0].shape\n",
    "frames = []\n",
    "frames_per_img = 5\n",
    "draw_distance = 30\n",
    "for i in range(0, frames_per_img * (len(imgs) - 1)):\n",
    "    t = i / frames_per_img\n",
    "    lower = int(math.floor(t))\n",
    "    \n",
    "    A = lerpiform(w, h, Ts[lower + 1], t - lower)\n",
    "    \n",
    "    def dotreduce(ms):\n",
    "        if not len(ms):\n",
    "            return np.identity(3)\n",
    "        return functools.reduce(np.dot, ms)\n",
    "    \n",
    "    transformed_images = [\n",
    "        cv2.warpPerspective(\n",
    "            imgs[j],\n",
    "            A @ dotreduce(Ts[lower + 1:j + 1]),\n",
    "            (w, h)\n",
    "        ) for j in range(lower, min(len(imgs), lower + draw_distance))\n",
    "    ]\n",
    "    out = combine_many(transformed_images)\n",
    "    \n",
    "    #out = lerpywarp(imgs[0], imgs[1], M, t)\n",
    "    \n",
    "    frames.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg -framerate 60 -i '/var/folders/_0/fccdb5xj0xn7y98d377jxzjc0000gn/T/tmpaqy6poln/%10d.jpg' -pix_fmt yuv420p -r 60 -vf 'pad=ceil(iw/2)*2:ceil(ih/2)*2' out_rigid5.mp4\n"
     ]
    }
   ],
   "source": [
    "common.videosave(\"out_rigid5.mp4\", frames, fps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
