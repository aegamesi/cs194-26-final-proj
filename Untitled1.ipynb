{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = \"/Users/eli/Downloads/2011_09_26/2011_09_26_drive_0002_sync/image_00/data/\"\n",
    "basedir = \"/Users/eli/Downloads/2011_09_26 2/2011_09_26_drive_0027_sync/image_00/data/\"\n",
    "\n",
    "#basedir = \"/Users/eli/Dropbox/Code/school/cs194-26/final_proj/streetviewimgs2/\"\n",
    "#basedir = \"/Users/eli/Downloads/2011_09_28/2011_09_28_drive_0002_sync/image_03/data/\"\n",
    "\n",
    "#basedir = \"/Users/eli/Downloads/2011_10_03/2011_10_03_drive_0042_sync/image_00/data/\"\n",
    "\n",
    "#basedir = \"/Users/eli/Downloads/rotterdam/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdlib\n",
    "import io\n",
    "import importlib\n",
    "import functools\n",
    "import math\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "# first party\n",
    "import common\n",
    "importlib.reload(common)\n",
    "\n",
    "# third party\n",
    "from contexttimer import Timer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# SciPy / OpenCV\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import skimage.io as skio\n",
    "import skimage as sk\n",
    "import IPython\n",
    "import PIL.Image\n",
    "import IPython.display\n",
    "import scipy.ndimage\n",
    "import scipy\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lerp(a, b, t):\n",
    "    return (b - a) * t + a\n",
    "\n",
    "def combine(a, b):\n",
    "    return np.multiply(a, (1 - np.ma.masked_where(b != 0, b).mask)) + b\n",
    "\n",
    "def combine_mask(a, b, mask):\n",
    "    return np.multiply(a, 1 - mask) + np.multiply(b, mask)\n",
    "\n",
    "def combine_many(ims):\n",
    "    return functools.reduce(lambda a, b: combine(b, a), ims[::-1])\n",
    "\n",
    "def transform_pts(pts, M):\n",
    "    \"\"\"\n",
    "    pts is like np.float32([[x, y], [x1, y1], [x2, y2]]...)\n",
    "    \n",
    "    \"\"\"\n",
    "    trans = cv2.perspectiveTransform(pts.reshape(-1, 1, 2), M)\n",
    "    return trans.reshape(pts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_homography(args):\n",
    "    im1, im2 = args\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    \n",
    "    kp1, des1 = sift.detectAndCompute(im1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(im2, None)\n",
    "    \n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "    \n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.9*n.distance:\n",
    "            good.append(m)\n",
    "            \n",
    "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,2)\n",
    "    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,2)\n",
    "    \n",
    "    \n",
    "    #M = common.get_homography(src_pts, dst_pts)\n",
    "    \n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 20.0)\n",
    "    M = cv2.estimateRigidTransform(src_pts, dst_pts, False)\n",
    "    if M is None:\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 20.0)\n",
    "        print(\"***\")\n",
    "    else:\n",
    "        M = np.vstack([M, np.float32([[0, 0, 1]])])\n",
    "    \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lerpiform(w, h, M, t):\n",
    "    \"\"\"\n",
    "    Computes A_(b -> a, t) from T_(b -> a)\n",
    "    \n",
    "    Computes the matrix needed to transform an image warped from the viewport (0 -> w, 0 -> h)\n",
    "    and then lerp it back to the viewport with parameter t.\n",
    "    \"\"\"\n",
    "    \n",
    "    # transform corners to the inner image's corners\n",
    "    corners = np.float32([[0,0], [0,h-1], [w-1,h-1], [w-1,0] ])\n",
    "    inner_corners = transform_pts(corners, M)\n",
    "\n",
    "    # lerp inner corners towards the outer corners\n",
    "    lerped = lerp(inner_corners, corners, t)\n",
    "\n",
    "    # find a new matrix to go from outer corners to lerped inner corners\n",
    "    M2 = cv2.getPerspectiveTransform(inner_corners, lerped)\n",
    "\n",
    "    return M2\n",
    "\n",
    "def lerpywarp(im_inner, im_outer, M, t):\n",
    "    h, w = im_inner.shape\n",
    "    M2 = lerpiform(w, h, M, t)\n",
    "\n",
    "    im_inner_2 = cv2.warpPerspective(im_inner, M2 @ M, (w, h))\n",
    "    im_outer_2 = cv2.warpPerspective(im_outer, M2, (w, h))\n",
    "\n",
    "    return im_inner_2 #(im_outer_2 + im_inner_2) * 0.5#combine(im_outer_2, im_inner_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_homographies(imgs):\n",
    "    \"\"\"\n",
    "    Takes in a list of images, computes homographies between each image\n",
    "    and its successive image, the first one is always the identity matrix.\n",
    "    \"\"\"\n",
    "    args = [(imgs[i + 1], imgs[i]) for i in range(len(imgs) - 1)]\n",
    "    with Pool() as p:\n",
    "        homs = list(tqdm(p.imap(find_homography, args), total=len(args)))\n",
    "        #homs = list(tqdm((find_homography(x) for x in args), total=len(args)))\n",
    "        #pass\n",
    "    #homs = list(tqdm((find_homography(x) for x in args), total=len(args)))\n",
    "    \n",
    "    return [np.identity(3)] + homs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs = [common.imread(basedir + \"%010d.png\" % i, as_float=False) for i in range(0, 188, 1)]\n",
    "print(\"Loading images\")\n",
    "filenames = sorted([x for x in os.listdir(basedir) if any(x.endswith(e) for e in ('.png', '.jpg'))])\n",
    "#filenames = filenames[200:600]\n",
    "imgs = list(tqdm((cv2.imread(os.path.join(basedir, f), 0) for f in filenames), total=len(filenames)))\n",
    "#imgs = [cv2.imread(basedir + \"%010d.png\" % i, 0) for i in range(0, 1170, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop images\n",
    "imgs = [x[200:-200,:] for x in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Computing homographies:\")\n",
    "with Timer() as t:\n",
    "    # Ts = [np.identity(3)] + [find_homography(imgs[i + 1], imgs[i]) for i in range(len(imgs) - 1)]\n",
    "    Ts = pairwise_homographies(imgs)\n",
    "print(\"computed {} homographies in {}\".format(len(Ts), t.elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_frame(args):\n",
    "    t, context = args\n",
    "    imgs, Ts, mask, w, h, draw_distance = context\n",
    "    lower = int(math.floor(t))\n",
    "    A = lerpiform(w, h, Ts[lower + 1], t - lower)\n",
    "\n",
    "    transformed_images = []\n",
    "    im = None\n",
    "    for j in range(lower, min(len(imgs), lower + draw_distance)):\n",
    "        M = functools.reduce(np.dot, [A] + Ts[lower + 1:j + 1])\n",
    "        im_trans = cv2.warpPerspective(imgs[j], M, (w, h))\n",
    "        mask_trans = cv2.warpPerspective(mask, M, (w, h))\n",
    "        \n",
    "        if im is None:\n",
    "            im = im_trans\n",
    "        else:\n",
    "            im = combine_mask(im, im_trans, mask_trans)\n",
    "            \n",
    "    return im\n",
    "    \n",
    "def final_video(imgs, Ts, speed=1.0, draw_distance=30, mask_r=32):\n",
    "    h, w = imgs[0].shape[:2]\n",
    "    \n",
    "    # compute mask\n",
    "    mask = np.zeros((h, w))\n",
    "    mask[mask_r:-mask_r,mask_r:-mask_r] = 1.0\n",
    "    mask = scipy.ndimage.gaussian_filter(mask, sigma=(mask_r * 0.5))\n",
    "    if len(imgs[0].shape) == 3:\n",
    "        mask = np.dstack([mask] * imgs[0].shape[-1])\n",
    "    \n",
    "    # compute timestamps to make frames at\n",
    "    \n",
    "    dets = [min(1.0, np.linalg.det(x)) for x in Ts]\n",
    "    logdets = [-math.log(x) for x in dets]\n",
    "    cdf = [sum(logdets[:i+1]) for i in range(len(logdets))]\n",
    "    \n",
    "    numframes = speed * len(imgs)\n",
    "    \n",
    "    timestamps = []\n",
    "    for y in np.linspace(cdf[0], cdf[-1], int(numframes)):\n",
    "        ind = max(0, np.searchsorted(cdf, y, side='right') - 1)\n",
    "        if ind + 1 >= len(cdf):\n",
    "            break\n",
    "        lval, rval = cdf[ind], cdf[ind + 1]\n",
    "        percent = (y - lval) / (rval - lval)\n",
    "        t = ind + percent\n",
    "        timestamps.append(t)\n",
    "\n",
    "    with Pool() as p:\n",
    "        context = (imgs, Ts, mask, w, h, draw_distance)\n",
    "        inputs = [(t, context) for t in timestamps]\n",
    "        #frames = p.imap(_compute_frame, inputs, chunksize=20)\n",
    "        frames = (_compute_frame(x) for x in inputs)\n",
    "        frames = list(tqdm(frames, total=len(inputs)))\n",
    "        \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Compositing frames\")\n",
    "with Timer() as t:\n",
    "    frames = final_video(imgs, Ts, speed=3.63829787, draw_distance=100)\n",
    "print(\"computed {} frames in {}\".format(len(frames), t.elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving video\")\n",
    "# common.videosave(\"out_dataset_1_skip5_bw_masked_speed1_draw100.mp4\", frames, fps=60)\n",
    "common.videosave(\"out_orig_2_smooth_cropped_speed3.6_draw100.mp4\", frames, fps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
